# ASR-LLM-TTS Demo

本项目是一个集成语音识别（ASR）、大语言模型（LLM）和语音合成（TTS）的语音对话 Demo，基于 [ABexit/ASR-LLM-TTS](https://github.com/ABexit/ASR-LLM-TTS) 进行修改和扩展，支持本地运行及 API 部署，适合集成到各种实时语音对话场景中。

---

## ✨ 功能简介

- **语音识别（ASR）：** 使用 `SenseVoiceSmall` 中文模型。
- **大语言模型（LLM）：**
  - 本地部署（如 `AutoModelForCausalLM`）；
  - 或接入外部 API（如 Qwen 2.5、Dify 等）。
- **语音合成（TTS）：** 使用 `VITS` 进行高质量中文语音合成。
- **支持模式：**
  - 本地命令行对话（按回车录音）
  - 实时麦克风监听模式
  - 对外 API 服务接口，适用于网页或系统集成

---

## 🖥️ 性能参考

在 NVIDIA RTX 3060 (12GB 显存) 环境下，单轮语音对话各模块平均耗时如下：

| 模块             | 平均耗时  |
|------------------|-----------|
| 语音识别（ASR）   | 0.13 秒   |
| 大模型推理（LLM） | 0.44 秒   |
| 语音合成（TTS）   | 0.63 秒   |
| **总耗时**         | **1.20 秒** |

> ⚡ 实测数据基于短语音输入，仅供参考，实际延迟受硬件配置与请求内容影响。

---

## 📁 项目文件说明

| 文件名               | 描述                                                                 |
|----------------------|----------------------------------------------------------------------|
| `main.py`            | 使用麦克风进行语音对话，结合本地 Qwen2.5 推理与 VITS 合成。按回车控制录音开始/结束。 |
| `lingyin.py`         | 实时监听麦克风持续对话，适合无缝交互式语音体验。                         |
| `main-dify.py`       | 麦克风语音输入 + Dify API 推理 + VITS 合成，适用于云端 LLM 接入。         |
| `main-dify-api.py`   | 提供标准 HTTP API 接口，支持外部系统调用 ASR、TTS、文本推理合成音频。        |

---

## 🚀 快速开始

### 1. 安装依赖
